epochs: 300
total_images: 60786 
global_batch_size: 4096  # 128 * 4 * 8
output_dir: output_dir

model:
  name: CLIPWrapper
  model_name: 'RN50'  # 'ViT'
  architecture: 
    name: CLIP
    embed_dim: 1024
    image_resolution: 224
    vision_layers: [3, 4, 6, 3]
    vision_width: 256
    vision_patch_size: 0
    context_length: 77
    vocab_size: 49408
    transformer_width: 512
    transformer_heads: 8
    transformer_layers: 12
  minibatch_size: 0


dataloader:
  train:
    num_workers: 8
    sampler:
      batch_size: 128 
      shuffle: true
      drop_last: True
    dataset:
      name: TextImageDataset 
      dataroot: /dbq/common/datasets/VL/FOOD101/captions/
      transforms:
        - name: ToRGB
        - name: RandomResizedCrop
          size: 224
          scale: [0.75, 1.]
          ratio: [1., 1.]
        - name: ToTensor 
        - name: Normalize
          mean: [0.48145466, 0.4578275, 0.40821073]
          std: [0.26862954, 0.26130258, 0.27577711]
      shuffle: False

lr_scheduler:
  name: CosineWarmup
  learning_rate: 4.8
  T_max: 93835
  warmup_steps: 3127
  start_lr: 0.0048
  end_lr: 4.8


optimizer:
  name: LarsMomentumOptimizer
  momentum: 0.9
  lars_weight_decay: 1.0e-6
  exclude_from_weight_decay: ['.bias', 'bn', 'batch_norm', '.b_0']
  epsilon: 1e-9


log_config:
    name: LogHook
    interval: 1